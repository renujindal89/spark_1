{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c9666-0637-4993-addf-38b675c82e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate spark310\n",
    "jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f2a42-b139-42b6-9137-4cdf43eac617",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0584bd-5368-480b-8760-6963f996095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"C:/Users/complere/anaconda3/envs/pyspark_env/python.exe\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"C:/Users/complere/anaconda3/envs/pyspark_env/python.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510b2d6-6acd-442b-aed5-22fadc3db263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64a713-3e1e-4a53-8d2d-b846966a0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717aefe-f495-494d-97ec-b9ae4a2c7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"Ram\", 25), (\"Shyam\", 30), (\"Geeta\", 28)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e13e1e-81bd-4dec-aa51-678ddba6af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark is a fast data processing system used for big data analysis\n",
    "Spark work in distributed mode ( split work across multiple machine)\n",
    "Spark is used for fast computation on huge dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea99f55-da58-460a-88c6-dc78068aaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster means joining the node \n",
    "why we combine- to distribute our task\n",
    "these clusters work in parellel and delivered te result  very fast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b18ac17-777f-4ad4-9fa4-bd8800faf6ab",
   "metadata": {},
   "source": [
    "# spark architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea45ac-44ff-4651-ae24-9b8d2b754021",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster is a group of machine \n",
    "cluster is having 3 node \n",
    "task is to precess 1tb data\n",
    "every spark cluster has a manager . it will use one node to create driver program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d83737-4a1e-43de-a7b6-148f0dffe948",
   "metadata": {},
   "source": [
    "# Driver Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea64c80-6e5b-4ed8-93a1-d6f195c6f06e",
   "metadata": {},
   "source": [
    "1. Driver Program\n",
    "\n",
    "This runs on the main machine (your laptop or master node).\n",
    "\n",
    "Contains SparkContext (or SparkSession in newer versions).\n",
    "\n",
    "Responsible for:\n",
    "‚úîÔ∏è It will break your code  into  small tasks\n",
    "‚úîÔ∏è Sending tasks to cluster manager ( no of machine reuired to execute this task,what actually need to happens )\n",
    "     just like a brain \n",
    "‚úîÔ∏è Collecting results back from the worker node \n",
    "‚úîÔ∏è Tracking job progress as well \n",
    "\n",
    "üìå Think of Driver as the brain of the job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc32ab-fc38-4042-9044-8eb85b1a1a05",
   "metadata": {},
   "source": [
    "2. SparkContext\n",
    "\n",
    "It is the entry point to Spark.\n",
    "\n",
    "It tells Spark how to connect to the cluster manager.\n",
    "eg.\n",
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()\n",
    "Here, SparkSession internally creates SparkContext."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e8441-b3b6-4a29-8db9-9896d434d2d9",
   "metadata": {},
   "source": [
    "# Cluster Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f372d8a8-294f-46ba-b2aa-8144c0ae0721",
   "metadata": {},
   "source": [
    "Cluster Manager\n",
    "\n",
    "It allocates resources (CPU + RAM) to Spark.\n",
    "now it has some instruction \n",
    "create a worker node on both machine \n",
    "It is responsible for deciding which worker will run the tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc5539-264b-47c3-8ed3-12f16bf0f40a",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è 4. Worker Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ddbe9a-d602-41ca-81dd-2d7b37e99c6b",
   "metadata": {},
   "source": [
    "üñ•Ô∏è 4. Worker Nodes\n",
    "\n",
    "Actual machines in the cluster\n",
    "\n",
    "Do the real work (computations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684a054-3669-4b21-9964-364864cced5a",
   "metadata": {},
   "source": [
    "Each Worker node contains:\n",
    "\n",
    "‚úîÔ∏è Executor\n",
    "\n",
    "JVM process running on each worker\n",
    "\n",
    "Runs tasks assigned by the driver\n",
    "\n",
    "Stores data in memory for caching\n",
    "\n",
    "‚úîÔ∏è Cache (In-Memory Storage)\n",
    "\n",
    "When you use .cache() or .persist()\n",
    "\n",
    "Data stays in memory (RAM) for faster reuse\n",
    "\n",
    "‚úîÔ∏è Tasks\n",
    "\n",
    "Smallest unit of work\n",
    "\n",
    "Example: map, filter, reduce tasks\n",
    "\n",
    "üìå Worker = Labour\n",
    "üìå Executor = Machine\n",
    "üìå Task = Work given"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae0c9e-1c23-498f-ad23-967af63ed10c",
   "metadata": {},
   "source": [
    "# Overall Flow"
   ]
  },
  {
   "cell_type": "raw",
   "id": "101b8d0a-f6e3-4c6f-8e5c-df8ac302e0ea",
   "metadata": {},
   "source": [
    "1.Driver sends job ‚Üí SparkContext creates execution plan.\n",
    "2.Plan goes to Cluster Manager ‚Üí allocate executors on workers.\n",
    "3.Executors on Worker nodes run small chunks called tasks.\n",
    "4.Results ‚Üí returned to Driver after completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad666f-8225-4b0a-9e84-b7d2e42e8aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7291c1-931e-4e6b-b1c2-ae7ae8a07a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d437bc-4809-43ea-a32c-56dd9dbc1b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5d9753e-face-4d1e-b2b2-b58d752df68e",
   "metadata": {},
   "source": [
    "# Structured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342d275-b2db-45b6-8b60-e47d27751f03",
   "metadata": {},
   "source": [
    "Structured Data\n",
    "Data that is organized in a fixed format (rows & columns), like a table.\n",
    "\n",
    "‚úî Features:\n",
    "\n",
    "Has a predefined schema (column names & data types)\n",
    "Easy to search, filter, and analyze\n",
    "Stored in databases, data warehouses\n",
    "SQL can be used to query it\n",
    "\n",
    "Formats:\n",
    "\n",
    "Excel (.xlsx)\n",
    "CSV (.csv)\n",
    "SQL tables\n",
    "Oracle, MySQL, PostgreSQL tables\n",
    "\n",
    "üìå Spark Use:\n",
    "\n",
    "üè∑ Best handled by DataFrame / Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a1ef17-33cd-4398-bb40-084dda0c02ed",
   "metadata": {},
   "source": [
    "# Unstructured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ac267-4a35-4a4f-a9e8-c35d8cfd98d5",
   "metadata": {},
   "source": [
    "Unstructured Data\n",
    "Data that does not follow a fixed format or table structure.\n",
    "\n",
    "‚úî Features:\n",
    "\n",
    "No predefined schema\n",
    "Hard to search and analyze directly\n",
    "Requires processing before use (cleaning, parsing)\n",
    "\n",
    "üìä Examples:\n",
    "\n",
    "Text messages\n",
    "WhatsApp chats\n",
    "Emails\n",
    "Images\n",
    "Audio files\n",
    "Videos\n",
    "PDF documents\n",
    "Log files\n",
    "\n",
    "üìÅ Formats:\n",
    "\n",
    ".txt\n",
    ".jpg / .png\n",
    ".mp4\n",
    ".mp3\n",
    ".pdf\n",
    "\n",
    "üìå Spark Use:\n",
    "\n",
    "üè∑ Best handled by RDD (raw, flexible structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee38847f-3698-44df-841a-7ae98ecb201c",
   "metadata": {},
   "source": [
    "# Semi-Structured Data(Bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb41248-779c-4e41-8fc6-450190a5f0d3",
   "metadata": {},
   "source": [
    "Semi-Structured Data (Bonus)\n",
    "Data is not in a table but still has tags/markers that organize it.\n",
    "\n",
    "üìä Examples:\n",
    "\n",
    "JSON\n",
    "XML\n",
    "HTML\n",
    "YAML\n",
    "\n",
    "‚úî Format Example (JSON)\n",
    "{\n",
    "  \"name\": \"Rahul\",\n",
    "  \"age\": 28,\n",
    "  \"city\": \"Pune\"\n",
    "}\n",
    "\n",
    "üìå Spark Use:\n",
    "\n",
    "Handled easily by DataFrame because it can infer schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d437be-a795-4cf3-9cd9-db9b33b367aa",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed72e2d-1192-493c-9da5-5bebc6795108",
   "metadata": {},
   "source": [
    "Structured data ‚Üí tabular, clean, SQL-friendly ‚Üí use DataFrame\n",
    "\n",
    "Unstructured data ‚Üí raw, no format ‚Üí use RDD\n",
    "\n",
    "Semi-structured ‚Üí has tags ‚Üí JSON/XML ‚Üí DataFrame works best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e106e-4805-43a8-aa1f-5b7b43642127",
   "metadata": {},
   "source": [
    "# RDD and Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7f931-5116-468c-9915-8b2a6c3820e1",
   "metadata": {},
   "source": [
    "What is RDD?\n",
    "\n",
    "RDD (Resilient Distributed Dataset) is the lowest level data structure in Spark.\n",
    "   1Ô∏è‚É£ Resilient\n",
    "\n",
    "Means fault-tolerant.\n",
    "If any worker node fails, RDD automatically recompute  lost data.\n",
    "It does not need to recompute everything, only the missing part.\n",
    "\n",
    "2Ô∏è‚É£ Distributed\n",
    "\n",
    "Means data is stored across multiple machines (nodes) in cluster.\n",
    "‚úî What distribution gives you:\n",
    "\n",
    "Parallel processing,\n",
    "Fast computation,\n",
    "Load sharing\n",
    "\n",
    "3Ô∏è‚É£ Dataset\n",
    "\n",
    "Means a collection of data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c73c3bc-076f-41d6-a446-4ce0e7964b42",
   "metadata": {},
   "source": [
    "RDD is simply:\n",
    "A collection (list/set) of elements\n",
    "Split into partitions\n",
    "Processed in parallel\n",
    "\n",
    "\n",
    "üî• Key Points:\n",
    "\n",
    "‚úî When to Use RDD\n",
    "When working with unstructured data (logs, text files)\n",
    "\n",
    "\n",
    "‚ö†Ô∏è When NOT to use RDD\n",
    "\n",
    "When you have structured data (use DataFrame instead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d1739-ce81-41b8-975f-629b7bc84771",
   "metadata": {},
   "source": [
    "# Why RDD is called Low-Level API?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc06313-6dfe-425d-900e-3274000346f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Because you write the entire processing logic:\n",
    "You decide how each value is transformed ‚Üí map\n",
    "You decide which values stay ‚Üí filter\n",
    "No schema, no column names.\n",
    "\n",
    "It uses functional transformations like:\n",
    "\n",
    "map\n",
    "filter\n",
    "reduce\n",
    "distinct\n",
    "union\n",
    "\n",
    "These are low-level operations because you control data element-by-element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a058f33-6ee1-49d2-8574-5e80f41b0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map\n",
    "map transforms each element of RDD.\n",
    "It applies a function to every record.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2975fd1f-1951-4c61-8da9-df968f387d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[22] at RDD at PythonRDD.scala:53\n",
      "[15, 25, 35, 45]\n"
     ]
    }
   ],
   "source": [
    "#RDD Example with Partitioning\n",
    "rdd = spark.sparkContext.parallelize([10, 20, 30, 40], 2)\n",
    "rdd1 = rdd.map(lambda x: x + 5)\n",
    "print(rdd1)\n",
    "print(rdd1.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079645b-8af2-4b5f-87b0-e9a10bad6bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RDD is a lazy evaluated distributed dataset.\n",
    "#Until you perform an action, Spark will not compute and show results.\n",
    "Use .collect() to fetch results from cluster to driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6fedabf-516c-4d8f-bb77-f223438208b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "mapped = rdd.map(lambda x: x * 2).collect()\n",
    "print(mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dab3d883-163c-4460-8179-7942db39ca42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "mapped = rdd.map(lambda x: x * 2)\n",
    "print(mapped.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918fed1b-c85f-4849-a85e-5ebd11443841",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is filter?\n",
    "üëâ filter selects elements that match a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f235790a-6dcd-4ff5-baff-d6ab25a4aef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 25]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([10, 15, 20, 25])\n",
    "filtered = rdd.filter(lambda x: x > 15).collect()\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2cd12fc-bdbb-4428-82c1-bfb3ff3c801c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[24] at RDD at PythonRDD.scala:53\n",
      "[25, 35, 45]\n"
     ]
    }
   ],
   "source": [
    "rdd2 = rdd1.filter(lambda x: x > 20)\n",
    "print(rdd2)\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4bc81d-fb22-4e66-9df6-ebb4b4acb692",
   "metadata": {},
   "source": [
    "# Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e793a-a2fd-45b4-ac3d-f6856b858aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "A DataFrame in Spark is a distributed collection of data organized into rows and columns, \n",
    "just like a table in SQL or Excel ‚Äî but stored across multiple machines for big data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e7157-9bf4-4f2c-a36e-d3088f077e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is a Spark DataFrame?\n",
    "\n",
    "A distributed table-like data structure\n",
    "\n",
    "Has schema (column names & data types)\n",
    "\n",
    "Built on top of RDDs\n",
    "\n",
    "Can process huge datasets in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3045da0-a0c3-460b-b9e1-05296839f111",
   "metadata": {},
   "source": [
    "# How to Create a DataFrame in PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50cafe-5770-4ff8-814a-b21985e01ff2",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ From Python List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4243293d-accc-4365-a6f7-3ce6755e58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4aa1b5e-dc92-4517-acf2-6fb480baddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "|  Ram| 25|\n",
      "|Shyam| 30|\n",
      "|Geeta| 28|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Ram\", 25), (\"Shyam\", 30), (\"Geeta\", 28)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c4dc3-9a2d-4b9a-ba1f-a90f6b648399",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ From CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05e483bb-64be-4152-9c13-33efc0a567c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "| id|   name|  age| gender|   salary| join_date|department|score|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|  Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|    Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3|Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|  david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|    Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|    Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|  Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|   NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9| Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|  Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"D:\\samples_data.csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01274f-c41b-44b0-bb7d-1cab4ca75878",
   "metadata": {},
   "source": [
    "# From JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2248c4-b6c0-4721-bb44-91c3923b48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"data.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7836fc6e-b9d2-416d-8e64-33f3b021d430",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ From Existing RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2598f9c-a453-456a-8984-ae8ef4db4afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|value|\n",
      "+---+-----+\n",
      "|  1|    A|\n",
      "|  2|    B|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([(1, \"A\"), (2, \"B\")])\n",
    "df = rdd.toDF([\"id\", \"value\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a9a95-3ac2-4c51-8844-0f0ecc5fa8c3",
   "metadata": {},
   "source": [
    "# üèÅ Why DataFrames are Preferred Over RDDs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e3a76c-b12c-4b97-8c22-ac1718488e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature              \t                     DataFrame\t                           RDD\n",
    "Performance          \t                     Faster (Catalyst optimizer)          \tSlower\n",
    "Schema(column name and datatype)\t          Yes\t                                 No\n",
    "Ease of Use\t                                  High\t                                    Low\n",
    "Use Case\t                                 SQL-like queries, ML\t               Low-level transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45798cec-1eb5-495f-a472-33eb7a2c49f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9289fe48-d13f-4ff5-b46c-5ea3f39de171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(1,100000)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0254a975-425f-485b-b9ae-e38f585bf19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo %JAVA_HOME%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c79f7a7f-ff3a-406a-b503-c45a41288a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908b29c-6cd2-4fa3-ae29-987dcea47f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!where java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9dfe73-55f8-496a-af54-117eceab870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "java version \"17.0.12\" 2024-07-16 LTS\n",
      "Java(TM) SE Runtime Environment (build 17.0.12+8-LTS-286)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 17.0.12+8-LTS-286, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bb189-aae9-402f-9b2b-6a0fe717e0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db1346-38c2-4406-9b10-2339704f28e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c9d0a-c012-4c3c-bea6-0d37184c9361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6b241-fecd-416b-ba4b-882a40589f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a318c-9c33-4fa9-8971-e2129d5b26b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d646024-f05a-458a-bee6-77c0f1eff596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf605dfb-0962-4709-87d9-02feda3316ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1616acf-b01f-419a-b3ad-e0ed0ec4173b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324e91c-85c6-4d8e-b9be-d749877dbd79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca1a99-b8cc-4eab-98b3-3b0d3cdecc83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac3ab3-0dec-4ddb-b238-d9605d5afb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684cc079-897b-433b-a62f-314a09e3d325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14806e-25c6-4e88-a7a0-793a1893e597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf3ba6-27eb-41c7-9928-98a8544d9540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a266f3-8d3b-4547-8e09-219b84451d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f601e3-dd54-49b7-b6ad-e697dd86564a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528cd63f-318e-4809-8647-27fcfda7428f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084553a6-b476-4e02-baaf-a639656c72ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b5f57-f8cd-4566-817b-0bf17fde0992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f9cae-c67a-4d41-a0d8-e220ec860d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d24eb0-4a5c-4f41-b826-655c053aee4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0ef5b-1021-4c74-bcd6-0c6b3a42fb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70989cbd-495c-4c66-ba3f-1ce7df3a822e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark Env",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
